# USAGE

# python predict_video.py --model model/activity_gpu.model --label-bin model/lb.pickle --input example_clips/cyclone_movie.mp4 --output output/cyclon_movie_output.avi --size 10

# import the necessary packages
from keras.models import load_model
from collections import deque
import numpy as np
import argparse
import pickle
import cv2
from twilio.rest import Client
def prediction(filename, o_filename):
    camid = 'IRNSS-1I'
    location = 'Geosynchronous / 55°E, 29° inclined orbit'
    
    # construct the argument parser and parse the arguments : 'example_clips/hurricane.mp4', 'output/hurricane_output.mp4'
    args = {'model':'model/activity_gpu.model' , 'label_bin':'model/lb.pickle', 'input':filename, 'output':o_filename, 'size':10}
    
    # load the trained model and label binarizer from disk
    print("[INFO] loading model and label binarizer...")
    model = load_model(args["model"])
    lb = pickle.loads(open(args["label_bin"], "rb").read())
    
    # initialize the image mean for mean subtraction along with the
    # predictions queue
    mean = np.array([123.68, 116.779, 103.939][::1], dtype="float32")
    Q = deque(maxlen=args["size"])
    
    # initialize the video stream, pointer to output video file, and
    # frame dimensions
    vs = cv2.VideoCapture(args["input"])
    writer = None
    (W, H) = (None, None)
    client = Client("ACea4cecca40ebb1bf4594098d5cef4541", "32789639585561088d5937514694e115") #update from twilio
    prelabel = ''
    ok = 'Normal'
    fi_label = []
    framecount = 0
    # loop over frames from the video file stream
    while True:
    	# read the next frame from the file
    	(grabbed, frame) = vs.read()
    
    	# if the frame was not grabbed, then we have reached the end
    	# of the stream
    	if not grabbed:
    		break
    
    	# if the frame dimensions are empty, grab them
    	if W is None or H is None:
    		(H, W) = frame.shape[:2]
    	framecount = framecount+1
    	# clone the output frame, then convert it from BGR to RGB
    	# ordering, resize the frame to a fixed 224x224, and then
    	# perform mean subtraction
    	output = frame.copy()
    	frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    	frame = cv2.resize(frame, (224, 224)).astype("float32")
    	frame -= mean
    
    	# make predictions on the frame and then update the predictions
    	# queue
    	preds = model.predict(np.expand_dims(frame, axis=0))[0]
    #	print('Preds = :', preds)
    	
    #	total = (preds[0]+ preds[1]+preds[2] + preds[3]+ preds[4]+preds[5])
    #	maximum = max(preds)
    #	rest = total - maximum
        
    #	diff = (.8*maximum) - (.1*rest)
    #	print('Difference of prob ', diff)
    #	th = 100
    #	if diff > .60:
    #		th = diff
    #	print('Old threshold = ', th)
        
        
    	prediction = preds.argmax(axis=0)
    	Q.append(preds)
    
    	# perform prediction averaging over the current history of
    	# previous predictions
    	results = np.array(Q).mean(axis=0)
    	print('Results = ', results)
    	maxprob = np.max(results)
    	print('Maximun Probability = ', maxprob)
    	i = np.argmax(results)
    	print('Maximun Probability = ', maxprob)
    	print(lb.get_params())
    	print(lb.classes_)
    	label = lb.classes_[i]
    	print(label) 
    	# label = lb[i]
    
    	rest = 1 - maxprob
        
    	diff = (maxprob) - (rest)
    	print('Difference of prob ', diff)
    	th = 100
    	if diff > .80:
    		th = diff
          
            
            
            
    	if (preds[prediction]) < th:
    		text = "Alert : {} - {:.2f}%".format((ok), 100 - (maxprob * 100))
    		cv2.putText(output, text, (35, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0, 255, 0), 5)
    	else:
    		fi_label = np.append(fi_label, label)
    		text = "Alert : {} - {:.2f}%".format((label), maxprob * 100)
    		cv2.putText(output, text, (35, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0, 255, 0), 5) 
    #		if label != prelabel:
    #			client.messages.create(to="<+country code>< receiver mobile number>", #for example +918255555555
    #                       from_="+180840084XX", #sender number can be coped from twilo
    #                       body='\n'+ str(text) +'\n Satellite: ' + str(camid) + '\n Orbit: ' + location)
    		prelabel = label    
    
    
    	# check if the video writer is None
    	if writer is None:
    		# initialize our video writer
    		fourcc = cv2.VideoWriter_fourcc(*"MJPG")
    		writer = cv2.VideoWriter(args["output"], fourcc, 30,
    			(W, H), True)
    
    	# write the output frame to disk
    	writer.write(output)
    
    	# show the output image
    	cv2.imshow("Output", output)
    	key = cv2.waitKey(1) & 0xFF
    
    	# if the `q` key was pressed, break from the loop
    	if key == ord("q"):
    		break
    print('Frame count', framecount)
    print('Count label', fi_label)
    # release the file pointers
    print("[INFO] cleaning up...")
    writer.release()
    vs.release()